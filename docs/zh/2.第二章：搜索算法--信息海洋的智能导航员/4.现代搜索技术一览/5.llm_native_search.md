---
title: LLM 原生搜索：生成式检索与高级 RAG 深度实战
createTime: 2025/12/19 14:00:00
---

## 🚀 LLM 原生搜索：从“匹配”迈向“认知”

> **生成式 AI 不仅仅是搜索的 UI，它正在重构底层索引与检索逻辑。** 本节将深入探讨 GraphRAG、Self-RAG 等技术的具体实现细节。

---

## 🧬 范式一：生成式检索 (Generative Retrieval)

### 1) 核心算法：DSI (Differentiable Search Index)
生成式检索试图取消“检索-排序”两阶段，直接让模型输出文档标识符。
- **语义标识符 (Semantic Identifiers)**：不使用随机数字，而是使用层次化聚类生成的 ID（如 `1.2.5` 表示：电子产品 > 手机 > 苹果）。
- **训练任务**：模型学习从 `Document Content -> DocID` 的映射，推理时则是 `Query -> DocID`。
- **落地挑战**：无法处理亿级动态更新。目前主要应用于 **闭域搜索**（如内部维基、受限文档集）。

---

## 🕸️ 范式二：高级 RAG 技术深挖

### 1) GraphRAG：突破局部向量检索的瓶颈
传统的向量检索（Top-K）只看局部相似度，无法回答“总结这 100 份报告中的核心风险”这种全局问题。

**具体实现流程 (Index 阶段)**：
1. **实体与关系抽取**：LLM 扫描全量文档，提取 `(实体A, 关系, 实体B)` 三元组。
2. **社区检测 (Community Detection)**：使用 **Leiden 算法** 对生成的图进行聚类，形成不同层级的“语义社区”。
3. **社区摘要 (Community Summaries)**：LLM 为每个社区生成总结性报告，并构建层次化索引。

**Query 阶段**：
- **全局查询 (Global Search)**：扫描所有社区摘要，合成最终答案（适合总结类问题）。
- **局部查询 (Local Search)**：结合向量检索找到的具体实体，并在图中进行 1-2 跳（Hop）扩展检索。

### 2) Self-RAG：带反思的检索框架
Self-RAG 引入了特殊的 **反思令牌 (Reflection Tokens)**，让模型具备“自知之明”。

- **[IsRel]**：判断检索到的片段是否与 Query 相关。
- **[IsSup]**：判断生成的答案是否被检索片段所支撑（减少幻觉）。
- **[IsUse]**：判断回答对用户是否有用。

**工作逻辑**：
1. **检索触发**：模型根据 Query 判定是否需要检索（输出 `[Retrieve]`）。
2. **多路径生成**：对召回的多个 K 片段并行生成结果。
3. **分值筛选**：根据反思令牌的概率分布（如 `IsSup` 的分数），加权选出最优路径。

---

## 🔍 范式三：纠错 RAG (Corrective RAG, CRAG)

**核心架构逻辑**：
1. **检索评估器 (Retrieval Evaluator)**：对检索到的文档打分。
2. **分类处理**：
   - **Correct (正确)**：直接进入生成阶段。
   - **Ambiguous (模糊)**：结合向量检索结果与 **Web Search (外部搜索)** 进行融合。
   - **Incorrect (错误)**：抛弃检索片段，完全依赖 Web Search 获取知识。

---

## 🛠️ 性能与工程踩坑点 (Hard Truths)

| 关键问题 | 深度对策 |
| :--- | :--- |
| **检索丢失 (Lost in the Middle)** | 模型对长上下文中间位置的感知弱。**对策**：将最重要的片段放在 Top 1 和 Bottom 1。 |
| **检索冗余** | 多个 Chunk 内容高度重复浪费 Token。**对策**：引入 **Maximal Marginal Relevance (MMR)** 算法进行结果去重。 |
| **幻觉控制** | 模型“脑补”不存在的事实。**对策**：在 Prompt 中强制要求 `“如果上下文未提及，请回答不知道”`，并结合 NLI 模型做离线验证。 |

---

## 🤔 思考题

> 1. **GraphRAG** 虽然强大，但索引成本（Token 消耗）可能是传统向量搜索的 100 倍以上。在什么场景下，这种投入是值得的？
> 2. 如果你的搜索系统只有 50ms 延迟预算，你还能使用 **Self-RAG** 的多路径反思机制吗？你会如何做精简？

::: tip 🎉 章节小结
生成式检索与高级 RAG 的本质是**引入更强的推理能力来弥补数据表示的不足**。通过 GraphRAG 构建全局视野，通过 Self-RAG 实现自我纠错，我们正在构建一个真正“懂”知识的搜索引擎。
:::
